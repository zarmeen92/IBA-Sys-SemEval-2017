{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For first submission,\n",
    "following were the features\n",
    "1. Tfidf\n",
    "2. unigram PMI lexicon features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zarmeen\\Anaconda2\\envs\\gl-env\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import logging\n",
    "import re\n",
    "import nltk.data\n",
    "from nltk.corpus import stopwords\n",
    "import pysentiment as ps\n",
    "#from practnlptools.tools import Annotator\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer() \n",
    "from __future__ import division\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Headlines Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_json(codecs.open('Headline_Trainingdata.json', 'r', 'utf-8'),orient='records')\n",
    "test_data = pd.read_json(codecs.open('Headlines_Testdata.json', 'r', 'utf-8'),orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(491, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1142, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morrisons</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430</td>\n",
       "      <td>Morrisons book second consecutive quarter of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMI</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>IMI posts drop in first-quarter organic revenu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glencore</td>\n",
       "      <td>4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>Glencore to refinance its short-term debt earl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryanair</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259</td>\n",
       "      <td>EasyJet attracts more passengers in June but s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>Barclays 'bad bank' chief to step down</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  id  sentiment                                              title\n",
       "0  Morrisons   2      0.430  Morrisons book second consecutive quarter of s...\n",
       "1        IMI   3     -0.344  IMI posts drop in first-quarter organic revenu...\n",
       "2   Glencore   4      0.340  Glencore to refinance its short-term debt earl...\n",
       "3    Ryanair   5      0.259  EasyJet attracts more passengers in June but s...\n",
       "4   Barclays   6     -0.231             Barclays 'bad bank' chief to step down"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ashtead</td>\n",
       "      <td>1144</td>\n",
       "      <td>Ashtead to buy back shares, full-year profit b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shell</td>\n",
       "      <td>1145</td>\n",
       "      <td>EU regulators clear Shell's takeover of BG Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prudential</td>\n",
       "      <td>1146</td>\n",
       "      <td>UK's FTSE has worst day so far in 2015 as BG a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GlaxoSmithKline</td>\n",
       "      <td>1147</td>\n",
       "      <td>GlaxoSmithKline acquires HIV assets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>1148</td>\n",
       "      <td>Barclays faces another heavy forex fine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           company    id                                              title\n",
       "0          Ashtead  1144  Ashtead to buy back shares, full-year profit b...\n",
       "1            Shell  1145   EU regulators clear Shell's takeover of BG Group\n",
       "2       Prudential  1146  UK's FTSE has worst day so far in 2015 as BG a...\n",
       "3  GlaxoSmithKline  1147                GlaxoSmithKline acquires HIV assets\n",
       "4         Barclays  1148            Barclays faces another heavy forex fine"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_lex = []\n",
    "score_lex = []\n",
    "def lex_SCL():\n",
    "    fname = 'SCL-NMA.txt'\n",
    "    f = open(fname)\n",
    "    for l in f.readlines():\n",
    "       \n",
    "        word,score = l.split('\\t')\n",
    "        words_lex.append(word)\n",
    "        score = score.replace('\\n','')\n",
    "        score_lex.append(float(score))\n",
    "    return words_lex,score_lex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_lex_pmi = []\n",
    "score_lex_pmi = []\n",
    "def lex_PMI():\n",
    "    fname = 'unigrams-pmilexicon.txt'\n",
    "    f = open(fname)\n",
    "    for l in f.readlines():\n",
    "       \n",
    "        word,score,pos,neg = l.split('\\t')\n",
    "        #print word\n",
    "        #print word.startswith('@')\n",
    "        if(word.startswith('@') == False and (word[0:3] != 'http')):\n",
    "            words_lex_pmi.append(word)\n",
    "            #score = score.replace('\\n','')\n",
    "            score_lex_pmi.append(float(score))\n",
    "      \n",
    "    return words_lex_pmi,score_lex_pmi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_lex,score_lex = lex_SCL()\n",
    "words_lex_pmi,score_lex_pmi = lex_PMI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44668"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_lex_pmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preprocessing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanText(text,companyName):\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \", text)\n",
    "    company = companyName.split(' ')\n",
    "    words = text.split()\n",
    "    words = [w for w in words if not w in stops and len(w) > 1 and w not in company]\n",
    "    return ( \" \".join(words) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for computing lexicon score\n",
    "def lex_score(text):\n",
    "    tokens = text.split(' ')\n",
    "    score = 0\n",
    "    for word in tokens:\n",
    "        for index in range(0,len(words_lex)):\n",
    "            if(word.isupper() == False):\n",
    "                if stemmer.stem(str(word.lower())) == stemmer.stem(words_lex[index]):\n",
    "                        score = score+score_lex[index]\n",
    "                        #print score\n",
    "                        #print word\n",
    "                        break\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lex_score_pmi(text):\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \", text)\n",
    "    text = re.sub('-',' ',text)\n",
    "    text = re.sub(\"'\",'',text)\n",
    "    words = nltk.word_tokenize(text)\n",
    "    tags = nltk.pos_tag(words)\n",
    "    score = 0\n",
    "    print tags\n",
    "    for word in tags:\n",
    "        if word[1] in ['VBD','JJR','JJ','VB','VBS','VBZ','VBN','VBG']:\n",
    "            print word[0]\n",
    "            for index in range(0,len(words_lex_pmi)):\n",
    "                if(word[0].isupper() == False):\n",
    "                    if word[0].lower() == words_lex_pmi[index].decode('utf-8'):\n",
    "                            score = score+score_lex_pmi[index]\n",
    "                            print words_lex_pmi[index]\n",
    "                            print score_lex_pmi[index]\n",
    "\n",
    "                            break\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Computing Harvard Lexicon scores\n",
    "hiv4 = ps.HIV4()\n",
    "def lex_score2(text):\n",
    "    tokens = hiv4.tokenize(text)  # text can be tokenized by other ways\n",
    "                                  # however, dict in HIV4 is preprocessed\n",
    "                                  # by the default tokenizer in the library\n",
    "    score = hiv4.get_score(tokens)\n",
    "\n",
    "    return score['Polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data['lex_score3'] = training_data['title'].apply(lex_score_pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data['lex_score2'] = training_data['title'].apply(lex_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data['lex_score3'] = test_data['title'].apply(lex_score_pmi)\n",
    "test_data['lex_score2'] = test_data['title'].apply(lex_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>lex_score2</th>\n",
       "      <th>lex_score3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.344</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.340</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.231</td>\n",
       "      <td>-0.999999</td>\n",
       "      <td>-0.909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  lex_score2  lex_score3\n",
       "0      0.430    0.000000       0.077\n",
       "1     -0.344    0.333333       1.304\n",
       "2      0.340    0.999999       0.334\n",
       "3      0.259    0.000000       1.019\n",
       "4     -0.231   -0.999999      -0.909"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[['sentiment','lex_score2','lex_score3']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Training Dataset into Train/Test for Internal Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(training_data[['id','title','lex_score3','lex_score2']],training_data[['sentiment']], test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer,r2_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def customerscorer(y,y_pred):\n",
    "    return cosine_similarity([y],[y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "X_training = vectorizer.fit_transform(X_train.title)\n",
    "X_testing = vectorizer.transform(X_test.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3), max_df=0.4,\n",
    "                                 stop_words='english')\n",
    "X_training = vectorizer.fit_transform(X_train.title)\n",
    "X_testing = vectorizer.transform(X_test.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_params = { 'max_depth':range(3,10,2),\n",
    "         'n_estimators': [80,100,150,200],\n",
    "        'subsample':[i/100.0 for i in range(40,90,5)],\n",
    "        'min_child_weight' :range(1,6,2),\n",
    "        'colsample_bytree' :[i/100.0 for i in range(40,90,5)],\n",
    "        'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100],\n",
    "        'learning_rate':[0.1,0.5],\n",
    "        'objective':['reg:linear'],\n",
    "        'scale_pos_weight' : [1,5,10,50,100]\n",
    "       }\n",
    "xgb_model = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(913, 2247)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229, 2247)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_feats =np.column_stack((X_training.toarray(),X_train['lex_score3']))\n",
    "test_feats =np.column_stack((X_testing.toarray(),X_test['lex_score3']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomizedSearchCV(xgb_model, x_params,cv = 5,scoring=cs_scorer)\n",
    "clf.fit(train_feats,y_train)\n",
    "#saved = save_model(clf,'models/acd','model_'+cat)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr = clf.predict(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test['predicted sentiment'] = pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.51963458]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(y_test['sentiment'],y_test['predicted sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':X_test['id'],'sentiment score' : y_test['sentiment']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1144</td>\n",
       "      <td>0.691899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1145</td>\n",
       "      <td>0.191305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1146</td>\n",
       "      <td>-0.373309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1147</td>\n",
       "      <td>0.083100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1148</td>\n",
       "      <td>-0.658537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  sentiment score\n",
       "0  1144         0.691899\n",
       "1  1145         0.191305\n",
       "2  1146        -0.373309\n",
       "3  1147         0.083100\n",
       "4  1148        -0.658537"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_json('submission.json',orient='records')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
