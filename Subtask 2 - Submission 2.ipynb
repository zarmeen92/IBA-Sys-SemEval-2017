{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import logging\n",
    "import re\n",
    "import nltk.data\n",
    "from nltk.corpus import stopwords\n",
    "import pysentiment as ps\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer() \n",
    "from __future__ import division\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import codecs\n",
    "import nltk.tag.stanford as st\n",
    "tagger = st.StanfordNERTagger('stanford-ner-2014-06-16/stanford-ner-2014-06-16/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
    "                             'stanford-ner-2014-06-16/stanford-ner-2014-06-16/stanford-ner.jar')\n",
    "\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Reading Lougran Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logran_dict = pd.read_csv('lougran.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_lougran = []\n",
    "neg_lougran = []\n",
    "for index,row in logran_dict.iterrows():\n",
    "    if row['Positive'] == 2009:\n",
    "        pos_lougran.append(row['Word'].lower())\n",
    "    if row['Negative'] == 2009:\n",
    "        neg_lougran.append(row['Word'].lower()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_lougran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2315"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_lougran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lex_Lougran():\n",
    "    words_neg_lougran = []\n",
    "    fname = 'Loughran_McDonald_AggregateIPOWordList.txt'\n",
    "    f = open(fname)\n",
    "    for l in f.readlines():\n",
    "       \n",
    "        word = l.strip().lower()\n",
    "        words_neg_lougran.append(word)\n",
    "       \n",
    "    return words_neg_lougran\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_neg_lougran = lex_Lougran()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2600"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_neg_lougran)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_json(codecs.open('Headline_Trainingdata.json', 'r', 'utf-8'),orient='records')\n",
    "test_data = pd.read_json(codecs.open('Headline_Testingdata.json', 'r', 'utf-8'),orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(491, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1142, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lougran_pos_count(text):\n",
    "    words = text.split()\n",
    "    pos_count = 0\n",
    "    for w in words:\n",
    "        if w.lower() in pos_lougran:\n",
    "            pos_count = pos_count+1\n",
    "    return pos_count\n",
    "\n",
    "def lougran_neg_count(text):\n",
    "    words = text.split()\n",
    "    neg_count = 0\n",
    "    for w in words:\n",
    "        if w.lower() in words_neg_lougran:\n",
    "            neg_count = neg_count+1\n",
    "    return neg_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Computing Lougran Sentiment Scores\n",
    "training_data['neg_count'] = training_data['title'].apply(lougran_neg_count)\n",
    "training_data['pos_count'] = training_data['title'].apply(lougran_pos_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data['neg_count'] = test_data['title'].apply(lougran_neg_count)\n",
    "test_data['pos_count'] = test_data['title'].apply(lougran_pos_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_lex = []\n",
    "score_lex = []\n",
    "def lex_SCL():\n",
    "    fname = 'SCL-NMA.txt'\n",
    "    f = open(fname)\n",
    "    for l in f.readlines():\n",
    "       \n",
    "        word,score = l.split('\\t')\n",
    "        words_lex.append(word)\n",
    "        score = score.replace('\\n','')\n",
    "        score_lex.append(float(score))\n",
    "    return words_lex,score_lex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_lex_pmi = []\n",
    "score_lex_pmi = []\n",
    "def lex_PMI():\n",
    "    fname = 'unigrams-pmilexicon.txt'\n",
    "    f = open(fname)\n",
    "    for l in f.readlines():\n",
    "       \n",
    "        word,score,pos,neg = l.split('\\t')\n",
    "        #print word\n",
    "        #print word.startswith('@')\n",
    "        if(word.startswith('@') == False and (word[0:3] != 'http')):\n",
    "            words_lex_pmi.append(word)\n",
    "            #score = score.replace('\\n','')\n",
    "            score_lex_pmi.append(float(score))\n",
    "      \n",
    "    return words_lex_pmi,score_lex_pmi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_lex,score_lex = lex_SCL()\n",
    "words_lex_pmi,score_lex_pmi = lex_PMI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44668"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_lex_pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['familar',\n",
       " 'emilio',\n",
       " 'on-site',\n",
       " 'supertramp',\n",
       " 'spinvox',\n",
       " 'studmuffin',\n",
       " 'bessst',\n",
       " 'rowling',\n",
       " 'winplace.at',\n",
       " 'wahooooooo']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_lex_pmi[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# not required for spans\n",
    "def cleanText(text,companyName):\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \", text)\n",
    "    tagged = tagger.tag(text.split())\n",
    "    company = companyName.split(' ')\n",
    "\n",
    "    newText = ''\n",
    "    for word in tagged:\n",
    "        if word[1] in ['ORGANIZATION','PERSON']:\n",
    "          \n",
    "            newText = newText +  ' '+ word[0].upper()\n",
    "        elif word[0] in company or word[0].isupper():\n",
    "            \n",
    "            newText = newText +  ' '+ word[0].upper()\n",
    "        else:\n",
    "           \n",
    "            newText = newText + ' ' + word[0].lower()\n",
    "            \n",
    "  \n",
    "   \n",
    "    words = newText.split()\n",
    "    words = [w for w in words if len(w) > 1]\n",
    "    return ( \" \".join(words) )\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleanTextArray = []\n",
    "for index,row in training_data.iterrows():\n",
    "    print index\n",
    "    cleanTextArray.append(cleanText(row['title'],row['company']))\n",
    "training_data['cleanText'] = cleanTextArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleanTextArray = []\n",
    "for index,row in test_data.iterrows():\n",
    "    print index\n",
    "    cleanTextArray.append(cleanText(row['title'],row['company']))\n",
    "test_data['cleanText'] = cleanTextArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lex_score(text):\n",
    "    #tokens = lm.tokenize(text)\n",
    "    #score = lm.get_score(tokens)\n",
    "    tokens = text.split(' ')\n",
    "    score = 0\n",
    "    for word in tokens:\n",
    "        for index in range(0,len(words_lex)):\n",
    "            if(word.isupper() == False):\n",
    "                if stemmer.stem(str(word.lower())) == stemmer.stem(words_lex[index]):\n",
    "                        score = score+score_lex[index]\n",
    "                        #print score\n",
    "                        #print word\n",
    "                        break\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lex_score_pmi(text):\n",
    "    #tokens = lm.tokenize(text)\n",
    "    #score = lm.get_score(tokens)\n",
    "    text = re.sub(\"[^a-zA-Z-]\",\" \", text)\n",
    "    #text = re.sub('-',' ',text)\n",
    "    #text = re.sub(\"'\",'',text)\n",
    "    words = nltk.word_tokenize(text)\n",
    "    tags = nltk.pos_tag(words)\n",
    "    print tags\n",
    "    #tokens = text.split(' ')\n",
    "    score = 0\n",
    "    print tags\n",
    "    for word in tags:\n",
    "        if word[1] in ['VBD','JJR','JJ','VB','VBS','VBZ','VBN','VBG','VBP','RB','RP']:\n",
    "            print word[0]\n",
    "            for index in range(0,len(words_lex_pmi)):\n",
    "                if(word[0].isupper() == False):\n",
    "                    if stemmer.stem(word[0]) == stemmer.stem(words_lex_pmi[index].decode('utf-8')):\n",
    "                            score = score+score_lex_pmi[index]\n",
    "                            print words_lex_pmi[index]\n",
    "                            print score_lex_pmi[index]\n",
    "\n",
    "                            break\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lm = ps.LM()\n",
    "hiv4 = ps.HIV4()\n",
    "def lex_score2(text):\n",
    "    #tokens = lm.tokenize(text)\n",
    "    #score = lm.get_score(tokens)\n",
    "    tokens = hiv4.tokenize(text)  # text can be tokenized by other ways\n",
    "                                  # however, dict in HIV4 is preprocessed\n",
    "                                  # by the default tokenizer in the library\n",
    "    score = hiv4.get_score(tokens)\n",
    "\n",
    "    return score['Polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data['lex_score3'] = training_data['cleanText'].apply(lex_score_pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data['lex_score2'] = training_data['cleanText'].apply(lex_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data['lex_score3'] = test_data['cleanText'].apply(lex_score_pmi)\n",
    "test_data['lex_score2'] = test_data['cleanText'].apply(lex_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Train and test data preparation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = training_data[['id','title','cleanText','lex_score3','lex_score2','pos_count','neg_count']]\n",
    "X_test = test_data[['id','title','cleanText','lex_score3','lex_score2','pos_count','neg_count']]\n",
    "y_train = training_data[['sentiment']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer,r2_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def customerscorer(y,y_pred):\n",
    "    return cosine_similarity([y],[y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs_scorer = make_scorer(r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# . TF-IDF Features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "X_training = vectorizer.fit_transform(X_train.title)\n",
    "X_testing = vectorizer.transform(X_test.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unigram Features\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "X_trainingGram = vectorizer.fit_transform(X_train.title)\n",
    "X_testingGram = vectorizer.transform(X_test.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameter tuning\n",
    "x_params = { 'max_depth':range(3,10,2),\n",
    "             'n_estimators': [100,150],\n",
    "             'min_child_weight' :range(1,6,2),\n",
    "             'objective':['reg:linear'],\n",
    "             'scale_pos_weight' : [1,5,10]\n",
    "       }\n",
    "xgb_model = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1142, 2503)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(491, 2503)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model 1- Feature Matrix\n",
    "train_feats =np.column_stack((X_training.toarray(),X_train['pos_count'],X_train['neg_count'],X_train['lex_score3'],X_train['lex_score2']))\n",
    "test_feats =np.column_stack((X_testing.toarray(),X_test['pos_count'],X_test['neg_count'],X_test['lex_score3'],X_test['lex_score2']))\n",
    "\n",
    "# Model 2- Feature Matrix\n",
    "train_feats1 =np.column_stack((X_trainingGram.toarray(),X_train['pos_count'],X_train['neg_count'],X_train['lex_score3'],X_train['lex_score2']))\n",
    "test_feats1 =np.column_stack((X_testingGram.toarray(),X_test['pos_count'],X_test['neg_count'],X_test['lex_score3'],X_test['lex_score2']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1- Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=500, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=23, silent=True, subsample=1)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = xgb.XGBRegressor(n_estimators=500,seed = 23)\n",
    "clf.fit(train_feats1,y_train.sentiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model2- Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=23, silent=True, subsample=1)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tfidf = xgb.XGBRegressor(n_estimators=100,seed = 23)\n",
    "clf_tfidf.fit(train_feats,y_train.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predictions from both models\n",
    "pr = clf.predict(test_feats1)\n",
    "pr_tfidf = clf_tfidf.predict(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Computing Mean predictions\n",
    "y_test = X_test[['id']]\n",
    "y_test['predicted sentiment'] = np.mean((pr,pr_tfidf),axis=0)\n",
    "y_train['predicted sentiment'] = np.mean((clf.predict(train_feats1),clf_tfidf.predict(train_feats)),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':X_test['id'],'sentiment score' : y_test['predicted sentiment']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1144</td>\n",
       "      <td>0.395600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1145</td>\n",
       "      <td>0.272562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1146</td>\n",
       "      <td>-0.395455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1147</td>\n",
       "      <td>0.170142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1148</td>\n",
       "      <td>-0.438649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  sentiment score\n",
       "0  1144         0.395600\n",
       "1  1145         0.272562\n",
       "2  1146        -0.395455\n",
       "3  1147         0.170142\n",
       "4  1148        -0.438649"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1144</td>\n",
       "      <td>0.691899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1145</td>\n",
       "      <td>0.191305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1146</td>\n",
       "      <td>-0.373309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1147</td>\n",
       "      <td>0.083100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1148</td>\n",
       "      <td>-0.658537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  sentiment score\n",
       "0  1144         0.691899\n",
       "1  1145         0.191305\n",
       "2  1146        -0.373309\n",
       "3  1147         0.083100\n",
       "4  1148        -0.658537"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Writing submission file\n",
    "submission.to_json('submission.json',orient='records')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
